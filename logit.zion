import sys {get_args}
import hash {Hashable, hash}
import logging {log, Info, Warn, Error}
import parser {choice, sequence, lift, OK}
import argparser {ArgParseState, parse_args, term, const, literal, flag}
import json {parse_json, J, from_json}
import note {Note}
import readline {readline}

let LOGIT_FILENAME = "logit.txt"


data Tracking {
  Tracking
  NonTracking
}

instance Str Tracking {
  fn str(tracking) => match tracking {
    Tracking => "Tracking"
    NonTracking => "NonTracking"
  }
}

struct Field {
  key String
  description String
}

instance Str Field {
  fn str(field) => match field {
    Field(key, desc) => "Field(${repr(key)}, ${repr(desc)})"
  }
}

newtype Category = Category(String, Tracking, [Field])
/*
struct Category {
  category_description String
  tracking             Tracking
  extra_fields         [Field]
}
*/

instance Str Category {
  fn str(cat) => match cat {
    Category(desc, tracking, fields) => "Category(${desc}, ${tracking}, ${fields})"
  }
}

data Command {
  GetNote(String)
  ListNotes
  ShowVersion
}

instance Str Command {
  fn str(cmd) => match cmd {
    GetNote(key) => "GetNote(${key})"
    ListNotes    => "ListNotes"
    ShowVersion  => "ShowVersion"
  }
}

fn get_note_command(x) => GetNote(str(x))

fn get_categories() Map String Category {
  /* Get categories. */
  return {
    "note": Category("Just a note", NonTracking, []),
    "todo": Category("TODO", Tracking, []),
    "url": Category("An URL", NonTracking, [Field("url", "URL: ")]),
    "health": Category("A health issue", NonTracking, []),
  }
}


fn get_version() String {
  /* Get version. */
  return "0.1"
}

fn get_arg_parser()  {
  # Get the argument parser
  return choice([
    const("list", ListNotes),
    const("version", ShowVersion),
    lift(get_note_command, choice([literal(key) for key in keys(get_categories())])),
  ])
}


/*
fn _get_install_config(read_config):
    install_config = None

    if read_config:
        config_filename = get_home_dir_path(".config/logit")
        try:
            with open(config_filename, "r") as f:
                install_config = json.load(f)

        except (IOError, ValueError):
            pass

    if install_config is None:
        # Create a new id for this installation
        install_config = {
            "uuid": str(uuid.uuid4()),
            "config_time": datetime.utcnow().isoformat(),
        }

        make_sure_path_exists(dirname(config_filename))

        with open(config_filename, "w") as f:
            json.dump(install_config, f, sort_keys=True, indent=4)

    assert install_config
    return install_config

*/
/*

fn get_install_id(read_config=True):
    """Get this installation"s ID"""
    return _get_install_config(read_config)["uuid"]

*/
/*

fn _create_backup_key_name():
    return (
        "{}-{}-{}"
        .format(datetime.utcnow().isoformat(), get_install_id(),
                LOGIT_FILENAME)
    )

*/
/*

fn get_s3_bucket(opts):
    """Get s3 bucket."""
    s3conn = boto.connect_s3(
        aws_access_key_id=opts.aws_access_key_id,
        aws_secret_access_key=opts.aws_secret_access_key)
    return s3conn.get_bucket(opts.s3_bucket)

*/
/*

fn _do_encrpyt_all(opts):
    """Do encrypt all."""
    get_secret_key(opts)
    new_secret_key = get_secret_key(AttrDict(),
                                    prompt="Enter a new password: ")
    new_secret_key_2 = get_secret_key(AttrDict(),
                                      prompt="Repeat your new password: ")
    if new_secret_key != new_secret_key_2:
        print("Passwords did not match.")
        return

    out = StringIO()
    for entry in _generate_entries_from_local_file(opts):
        encrypt_json(new_secret_key, entry, out)
        out.write("\r\n")
    out.seek(0)

    with open(opts.logit_filename, "w") as f:
        f.write(out.read())

*/
/*

fn _do_backup(opts):
    """Perform a backup to S3."""
    if (not opts.aws_access_key_id or
            not opts.aws_secret_access_key or
            not opts.s3_bucket):
        print("You must specify AWS access credentials and an S3 bucket name "
              "(see --help)")

    else:
        bucket = get_s3_bucket(opts)
        key = Key(bucket)
        key.key = _create_backup_key_name()
        key.set_contents_from_filename(opts.logit_filename)

*/
/*

fn logit(opts, entry, timestamp):
    try:
        entry["timestamp"] = timestamp.isoformat()
        entry["id"] = str(uuid.uuid4())
        entry["installation"] = get_install_id()

        assert "category" in entry
        entry["message"] = entry.get("message") or get_console_input("Notes: ")

        if entry.get("message"):
            with open(opts.logit_filename, "a") as f:
                secret_key = get_secret_key(opts)
                encrypt_json(secret_key, entry, f)
                f.write("\r\n")
        else:
            print("No logit entry entered.")
    finally:
        gc.collect()

*/
/*

fn parse_datetime(date_string):
    """Convert 2014-10-2 to a datetime, etc..."""
    return datetime(*[int(n) for n in date_string.split("-")])

*/
/*

fn print_recent_week(opts, categories):
    """Show a list of all entries from the recent week."""
    width, _ = get_terminal_size()
    week_ago = (datetime.utcnow() - timedelta(weeks=1)).isoformat()
    for entry in _generate_merged_entries_from_s3(opts):
        if entry["timestamp"] > week_ago:
            if not opts.category or entry.get("category") == opts.category:
                print_entry(entry, categories, width=width)

*/
/*

fn _do_logit(opts):
    categories = get_categories()
    category = opts.category

    while category not in categories:
        print("Existing categories:")

        for key, schema in categories.items():
            print("\t{}: {}".format(key, schema["description"]))

        category = get_console_input("Category: ")
        if not category:
            return

    opts.category = category

    if opts.show_recent_week:
        print_recent_week(opts, categories)

    entry = {"category": category}
    if opts.message:
        entry["message"] = opts.message

    fields = categories[category].get("fields") or {}
    for field, description in fields.items():
        value = get_console_input(description)
        if value:
            entry[field] = value

    timestamp = datetime.utcnow()
    if opts.back_date:
        timestamp = parse_datetime(opts.back_date)

    logit(opts, entry, timestamp)

*/
/*

fn _longest_category(categories):
    return max(len(category) for category in categories)

*/
/*
fn print_entry(entry, categories, prefix="", width=0):
    timestamp = entry.get("timestamp", "")
    if len(timestamp) == 19:
        timestamp = timestamp[:-3].replace("T", " ")
    elif len(timestamp) == 26:
        timestamp = timestamp[:-10].replace("T", " ")
    else:
        timestamp = None

    if not timestamp:
        timestamp = "-no timestamp-"

    category = (
        entry.get("category", "note").rjust(_longest_category(categories))
    )
    prefix_len = len("{prefix}{timestamp} : {category} : ".format(
        prefix=prefix,
        timestamp=timestamp,
        category=category,
    ))
    pretty_prefix = (
        (bcolors.MENU + prefix + bcolors.ENDC +
         bcolors.TIMESTAMP + "{timestamp}" + bcolors.ENDC +
         " : " + bcolors.CATEGORY + "{category}" + bcolors.ENDC +
         " : ").format(timestamp=timestamp, category=category)
    )
    message = entry.get("message")
    if prefix_len >= width:
        print(pretty_prefix + message)
    else:
        lines = textwrap.wrap(message, width - prefix_len) or [""]
        print(pretty_prefix + lines[0])
        for line in lines[1:]:
            print(" " * prefix_len + line)

*/
/*

fn _generate_entries_from_file(opts, file_, filename):
    """Generate all the entries from the local logit file"""
    for line, entry in enumerate(file_, start=1):
        if entry[0] != "{":
            try:
                yield decrypt_json(get_secret_key(opts), entry)
            except:
                log.exception("error decrypting entry %s" % entry)
        else:
            try:
                yield json.loads(entry)
            except ValueError:
                log.exception("error on line %d of %s", line, filename)

*/
/*

fn _generate_entries_from_local_file(opts, sort=False):
    """Generate all the entries from the local logit file"""
    filename = opts.logit_filename

    with open(filename, "r") as file_:
        if sort:
            for entry in _generate_sorted_entries_from_file(opts, file_,
                                                            filename):
                yield entry
        else:
            for entry in _generate_entries_from_file(opts, file_, filename):
                yield entry

*/
/*

fn _generate_entries_from_key(opts, key):
    file_ = StringIO(key.get_contents_as_string())
    for entry in _generate_entries_from_file(opts, file_, key.key):
        yield entry

*/
/*

fn _compare_entries_by_timestamp(x, y):
    if x.get("timestamp", "") < y.get("timestamp", ""):
        return -1
    else:
        return 1

*/
/*

fn _generate_sorted_entries_from_entries(entries):
    """Return all entries, sorted by time."""
    entries = sorted(entries, key=cmp_to_key(_compare_entries_by_timestamp))
    for entry in entries:
        yield entry

*/
/*

fn _generate_sorted_entries_from_file(opts, file_, filename):
    """Return all entries, sorted by time."""
    entries = sorted(list(_generate_entries_from_file(opts, file_, filename)),
                     key=cmp_to_key(_compare_entries_by_timestamp))
    for entry in entries:
        yield entry

*/
/*

fn _generate_incomplete_entries(opts, categories):
    incomplete_items = {}
    for entry in _generate_entries_from_local_file(opts):
        entry_category = entry.get("category")
        if opts.category is None or opts.category == entry_category:
            if categories.get(entry_category, {}).get("track_completion"):
                if "ref_id" in entry:
                    ref_id = entry.get("ref_id")
                    if entry.get("complete"):
                        del incomplete_items[ref_id]
                else:
                    incomplete_items[unique_id_from_entry(entry)] = entry

    return incomplete_items.itervalues()

*/
/*

fn _do_list(opts, categories, category=None):
    width, _ = get_terminal_size()
    for entry in _generate_entries_from_local_file(opts, sort=True):
        if not category or entry.get("category") == category:
            print_entry(entry, categories, width=width)

*/
/*

fn _do_check(opts):
    with open(opts.logit_filename, "r") as f:
        for line in f:
            json.loads(line)

    print("Looks good.")

*/
/*

fn _do_todo_list(opts, categories):
    """Show a menu for completing todo items"""
    width, _ = get_terminal_size()
    menu_items = list(enumerate(
        _generate_incomplete_entries(opts, categories),
        start=1))

    for index, entry in menu_items:
        print_entry(entry, categories, width=width, prefix=str(index) + ") ")

    try:
        completed_index = int(get_console_input(
            "Which entry did you complete [Enter to quit]? "))
    except ValueError:
        print("No entries changed.")
        return

    entry = dict(menu_items).get(completed_index)

    logit(opts, {
        "category": entry["category"],
        "ref_id": unique_id_from_entry(entry),
        "complete": True
    })
*/
/*
fn _get_installation_from_key_name(key_name):
    installation = key_name[27:63]
    if len(installation) == 36:
        return installation

*/
/*

fn _get_installations_from_keys(keys):
    installations = set()

    for key in keys:
        installation = _get_installation_from_key_name(key.key)
        if installation:
            installations.add(installation)

    return installations

*/
/*

fn _get_latest_key(keys, installation):
    """Get the latest key for an installation."""
    latest_key = None

    for key in keys:
        if installation in key.key:
            is_latest = (
                latest_key is None or
                latest_key.key < key.key
            )

            if is_latest:
                latest_key = key

    return latest_key

    */
    /*

fn _generate_merged_entries_from_s3(opts):
    """Merge all of the installations" logs into this installation."""
    bucket = get_s3_bucket(opts)
    keys = bucket.get_all_keys()

    # first find all of the installations
    installations = _get_installations_from_keys(keys)
    install_id = get_install_id()
    if install_id in installations:
        installations.remove(install_id)

    # for each installation, find the latest key
    keys_to_merge = {
        installation: _get_latest_key(keys, installation)
        for installation in installations
    }
    entries = {}
    for installation, key in keys_to_merge.items():
        for entry in _generate_entries_from_key(opts, key):
            if "installation" not in entry:
                entry["installation"] = installation
            entry_id = unique_id_from_entry(entry)
            entries[entry_id] = entry

    # now add any local entries
    for entry in _generate_entries_from_local_file(opts):
        if "installation" not in entry:
            entry["installation"] = install_id
        entry_id = unique_id_from_entry(entry)
        entries[entry_id] = entry

    for entry in _generate_sorted_entries_from_entries(entries.values()):
        yield entry

*/
/*

fn _do_merge(categories, opts):
    """Show the contents when merged from all installations."""
    width, _ = get_terminal_size()
    for entry in _generate_merged_entries_from_s3(opts):
        print_entry(entry, categories, width=width)

*/

fn main() {
  let argv = get_args()[1:]
  # Parse command line arguments
  let parser = get_arg_parser()
  with let command = parse_args(parser, argv) {
    handle_command(command)
  } else error {
    log(Error, "Error parsing arguments: ${error}")
  }
}

fn handle_command(command) {
  match command {
    GetNote(key) => get_note(key)
    ListNotes    => list_notes("/Users/wbbradley/logit.json")
    ShowVersion  => log(Info, get_version())
  }
}

fn parse_note_from_json(json J) => match from_json(json) {
  Just(note) => resource_acquired(note, ||{})
  Nothing    => ResourceFailure("parse_note_from_json: Malformed json ${json}")
}

fn parse_note_from_text(line String) WithElseResource Note String {
  return match parse_json(line) {
    Just(json) => parse_note_from_json(json)
  } else {
    ResourceFailure("parse_note_from_text: Unable to read json ${line}")
  }
}

fn list_notes(filename String) {
  var failed_lines = 0
  with let file = open(filename) {
    for line in readlines(file) {
      with let note = parse_note_from_text(line) {
        print(note)
      } else error {
        failed_lines += 1
        log(Warn, error)
      }
    }
    if failed_lines != 0 {
      log(Warn, "Failed to read ${failed_lines} entries from ${filename}")
    }
  } else errno {
    log(Error, errno)
  }
}

fn get_note(key String) {
  let categories = get_categories()
  if categories[key] is Just(Category(category_description, tracking, extra_fields)) {
    let line = readline("${category_description}: ")
    print("Got line ${repr(line)}")
  } else {

  }
}

